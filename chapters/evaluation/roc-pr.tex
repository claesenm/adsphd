\section{Constructing ROC and PR curve estimates} \label{roc-pr}

Next, we describe how to estimate bounds on the true ROC and PR curves. Though we focus on these two criteria, our approach can be used to estimate any metric based on contingency tables.% such as accuracy or F1. 
%Next, we discuss how to estimate bounds on the true ROC and PR curves. 


%For each of these curves, we can still apply the same basic procedure for constructing a ROC curve.  
{\bf ROC curves}
%Given a ranking, instead of constructing a single ROC curve, our approach computes two curves: one corresponding to the least upper bound and one corresponding to the greatest lower bound on rank CDF of all positives $\bothpos$. To construct these curves, we use the methodology outlined in Section 4 to compute two contingency tables for each possible rank $\ranksymb$, corresponding to the greatest lower bound and least upper bound on FPR. The set of contingency tables corresponding to greatest lower bounds on FPR at each rank are associated to an upper bound on the ROC curve of all positives $\bothpos$, whereas the set of contingency tables corresponding to the least upper bound on FPR corresponds to a lower bound on the ROC curve of $\bothpos$.
Given a ranking, instead of constructing a single ROC curve, our approach computes two curves: one corresponding to the upper bound and one corresponding to the lower bound on the CI on rank CDF of known positives $\knownpos$, using the methodology outlined in Section 4 to compute two contingency tables for each rank $\ranksymb$, corresponding to the greatest lower and least upper bound on $\FPR(\bothpos,r)$. The set of contingency tables corresponding to greatest lower bounds on FPR at each rank form an upper bound on the ROC curve of all positives $\bothpos$, whereas the set of contingency tables corresponding to the least upper bound on FPR form a lower bound on the ROC curve of $\bothpos$.


It is important to understand how these estimates correspond to bounds in ROC space. By computing $\theta$ as in Equation~\eqref{theta} to obtain the greatest lower bound on $\FPR(\latentpos,\ranksymb)$, the corresponding TPR is higher than $\TPR(\latentpos,\ranksymb)$. As such, the upper bound on the ROC curve is shifted upwards and to the left. Conversely, the lower bound on the ROC curve (based on the least upper bound on FPR at each rank, i.e. $\theta$ as in Equation~\eqref{theta-alt}) is shifted downward and to the right. This implies that the upper bound on the ROC curve completely dominates the curve of $\bothpos$ and the lower bound is completely dominated by the curve of $\bothpos$, provided that $\mathcal{T}_{lb}(\ranksymb) \leq \TPR(\latentpos,\ranksymb) \leq \mathcal{T}_{ub}(\ranksymb),\ \forall \ranksymb \in \{1,\ldots,|\overall|\}$.

{\bf Convergence properties} \label{convergence}
The convergence properties of our bounds are contingent on those of (a CI on) the empirical CDF:
via the strong law of large numbers the empirical CDF $\hat{F}_n(x)$ is a consistent pointwise estimator of the true CDF $F(x)$, converging uniformly for increasing $n$ \cite{van2000asymptotic}. % By the Glivenko-Cantelli theorem $\hat{F}_n(x)$ converges uniformly to $F(x)$ for increasing $n$ \cite{van2000asymptotic}. 

Figure~\ref{fig:convergence} shows the convergence of the bounds on area under the curve for the estimated lower and upper bound of the ROC curve for increasing amounts of known positives in simulated rankings. The range of bounds depends on the width of the CI on rank CDF, which in turn depends on the number of known positives (higher is better) and the size of the total data set (lower is better).


%Precision-Recall (PR) curves were originally used in information retrieval \citep{raghavan1989critical}. PR curves visualize the evolution of precision ($\TP / (\TP+\FN)$) versus recall (TPR) and can be used as an alternative to ROC curves to assess classifier performance. 

%Given the confusion matrices used to generate the least upper bound and greatest lower bound ROC curves, it is straightforward to construct the corresponding least upper bound and great lower bound PR curves. All that is required is to generate one PR point from each confusion matrix. 
{\bf PR curves} Given the contingency tables used to generate the least upper bound and greatest lower bound ROC curves, it is straightforward to construct the corresponding bounds in PR space. Each contingency table contains all the required information for generating a point in PR space. 

 A key result relating ROC and PR curves is that one curve dominates another in ROC space if and only if it also dominates in PR space~\citep{davis2006relationship}. Given this result, mapping the bounds we obtain for ROC curves to PR space directly yields (tight) bounds on the corresponding true PR curve. Since the upper bound in ROC space completely dominates the true curve, and the lower bound in ROC space is completely dominated by it, the same holds for the bounds on PR curves.

%PR curves are very sensitive to class skew. However, the empirical class balance is contingent on the estimated fraction $\hat{\pfrac}$ of positives in the unlabeled part of the test set. If the uncertainty on the estimate $\hat{\pfrac}$ is large, the bounds in PR space are inevitably loose (cfr. Figure~\ref{fig:results-covtype-pr}).


