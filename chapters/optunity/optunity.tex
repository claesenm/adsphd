\chapter{Easy Hyperparameter Search Using Optunity}\label{ch:optunity}

\hyphenation{Optunity}
\newcommand{\optunity}{{\sc Optunity}\xspace}

\chapterfrontpagesubmitted{
Claesen, M., Simm, J., Popovic, D., Moreau, Y., \& De Moor, B. (2015). 
\textbf{Easy hyperparameter search using Optunity},
\emph{Journal of Machine Learning Research}.
}{
Marc Claesen has developed, maintained, tested and documented the software in Python, MATLAB and Octave and took the lead in writing the initial draft, the revision and rebuttal of the paper.
}{
    \optunity is a free software package dedicated to hyperparameter optimization. It contains various types of solvers, ranging from undirected methods to direct search, particle swarm and evolutionary optimization. The design focuses on ease of use, flexibility, code clarity and interoperability with existing software in popular machine learning environments. \optunity is written in Python and contains interfaces to R, Octave and MATLAB.  \optunity uses a BSD license and is available at \texttt{\url{http://www.optunity.net}}.
}

\section{Introduction}
Many machine learning tasks involve training a model $\mathcal{M}$ which minimizes some loss function $\mathcal{L}(\mathcal{M}\ |\ \test)$ on given test data $\test$. A model is obtained via a learning algorithm $\mathcal{A}$ which uses a training set $\train$ and solves some optimization problem. The learning algorithm $\mathcal{A}$ may itself be parameterized by a set of hyperparameters $\lambda$, e.g. $\mathcal{M} = \mathcal{A}(\train\ |\ \lambda)$.  Hyperparameter search -- also known as tuning -- aims to find a set of hyperparameters $\lambda^*$, such that the learning algorithm yields an optimal model $\mathcal{M}^*$ that minimizes $\mathcal{L}(\mathcal{M}\ |\ \test)$:
\begin{equation}
\lambda^* = \argmin_{\lambda} \mathcal{L}\big(\mathcal{A}(\train\ |\ \lambda)\ |\ \test\big) = \argmin_{\lambda} \obj(\lambda\ |\ \mathcal{A},\ \train, \test,\ \mathcal{L}). \label{equation}
\end{equation}
In tuning, $\obj$ is the objective function and the hyperparameters $\lambda$ are optimization variables. The learning algorithm $\mathcal{A}$, loss function $\mathcal{L}$ and data sets $\train$ and $\test$ are known. %Depending on the learning task, $\train$ and $\test$ may be labeled and/or equal to each other. The objective function often has a constrained domain (for example regularization terms must be positive) and is assumed to be expensive to evaluate, black-box and non-smooth.

Tuning hyperparameters is a recurrent task in machine learning which may significantly affect overall performance. Commonly tuned hyperparameters are related to kernels, regularization, learning rates and network architecture. Some specific challenges associated to hyperparameter optimization are discussed by Claesen and De Moor \citep{claesen2015hyperparameter}. General machine learning packages provide only basic tuning methods like grid search \citep{pedregosa2011scikit}. In practice, the most common tuning approaches are grid search and manual tuning, though both are known to fail when the number of hyperparameters grows and manual search is additionally hard to reproduce \citep{bergstra2012random}.

\section{Optunity}
\optunity offers various optimizers and utility functions to enable efficient hyperparameter optimization using only a few of lines of code and minimal expertise. Our software is complementary to libraries that provide learning algorithms, such as \textsc{scikit-learn} \citep{pedregosa2011scikit}. The package uses a BSD license and is simple to deploy in any environment. \optunity supports Python, R, Octave and MATLAB on Linux, OSX and Windows.

\subsection{Functional Overview}
\optunity provides both simple routines for lay users and expert routines that enable fine-grained control of various aspects of the solving process. Basic tuning requires only an objective function, a maximum number of evaluations and box constraints on the hyperparameters to be optimized. Conditional search spaces in which the existence of some hyperparameters is contingent upon some discrete choice are also supported.

The objective function must be defined by the user. It takes a hyperparameter tuple $\lambda$ and typically involves three steps: (i) training a model $\mathcal{M}$ with $\lambda$, (ii) use $\mathcal{M}$ to predict a test set and (iii) compute some score or loss based on the predictions. %In unsupervised tasks, the separation between (i) and (ii) need not exist, for example in clustering a data set.

Tuning involves a series of function evaluations until convergence or until a predefined maximum number of evaluations is reached. \optunity is capable of vectorizing evaluations in the working environment to speed up the process at the end user's volition.

\optunity also provides $k$-fold cross-validation to estimate the generalization performance of supervised modeling approaches. The implementation can account for strata and clusters.\footnote{Instances in a stratum should be spread across folds. Clustered instances must remain in a single fold.} Finally, a variety of common quality metrics is available. 
The snippet below shows how to tune an SVM classifier with RBF kernel using {\sc scikit-learn} and \optunity:\footnote{We assume the correct imports are made and \texttt{data} and \texttt{labels} contain appropriate content.}


\begin{lstlisting}[style=Py, frame=none, xleftmargin=1.5ex, escapeinside={(*@}{@*)}]
!@optunity.cross_validated!(x=(*@\textcolor{red}{data}@*), y=(*@\textcolor{red}{labels}@*), num_folds=10, num_iter=2)
def (*@\textcolor{blue}{score}@*)(x_train, y_train, x_test, y_test, (*@\textcolor{blue}{C}@*), (*@\textcolor{blue}{gamma}@*)):
    model = sklearn.svm.SVC(C=10**(*@\textcolor{blue}{C}@*), gamma=10**(*@\textcolor{blue}{gamma}@*)).fit(x_train, y_train)
    decision_values = model.decision_function(x_test)
    return !optunity.metrics.roc_auc!(y_test, decision_values)

!hps!, _, _ = !optunity.maximize!((*@\textcolor{blue}{score}@*), num_evals=100, (*@\textcolor{blue}{C=[-5, 2]}@*), (*@\textcolor{blue}{gamma=[-5, 0]}@*)) (*@\label{optunity-maximize}@*)
svm = sklearn.svm.SVC(C=10**!hps['C']!, gamma=10**!hps['gamma']!) (*@\label{train-tuned-svm1}@*)
svm.fit((*@\textcolor{red}{data}@*), (*@\textcolor{red}{labels}@*)) (*@\label{train-tuned-svm2}@*)
\end{lstlisting}

The objective function as per Equation~\eqref{equation} is defined on lines 1 to 5, where $\lambda = (C, \gamma)$, $\mathcal{A}$ is the SVM training algorithm and $\mathcal{L}$ is area under the ROC curve. We use $2\times$ iterated 10-fold cross-validation to estimate area under the ROC curve. Up to $100$ hyperparameter tuples are tested in an exponential search space, bounded by $10^{-5} < C < 10^2$ and $10^{-5} < \gamma < 10^0$ on line \ref{optunity-maximize}. Finally, an SVM with optimized hyperparameters is trained on lines \ref{train-tuned-svm1} and \ref{train-tuned-svm2}.


\subsection{Available Solvers}
\optunity provides a wide variety of solvers, ranging from basic, undirected methods like grid search, sobol sequences and random search \citep{bergstra2012random} to evolutionary methods such as particle swarm optimization \citep{kennedy2010particle}, the covariance matrix adaptation evolutionary strategy (CMA-ES) \citep{hansen2001completely}, tree-structured Parzen estimator \citep{bergstra2011algorithms} and the Nelder-Mead simplex. The default solver is particle swarm optimization, which performs well for a large variety of tuning tasks involving various learning algorithms. Additional solvers will be incorporated in the future.
 
\subsection{Software Design and Implementation}

The design philosophy of \optunity prioritizes code clarity over performance. This is justified by the fact that objective function evaluations constitute the performance bottleneck. 

In contrast to typical Python packages, we avoid dependencies to facilitate users working in non-Python environments (sometimes at the cost of performance). To prevent issues for users that are unfamiliar with Python, care is taken to ensure all code in \optunity works out of the box on any Python version above 2.7, without requiring tools like \texttt{2to3} to make explicit conversions. \optunity has optional dependencies on {\sc DEAP} \citep{fortin2012deap} and {\sc Hyperopt} \citep{bergstra2013hyperopt} for the CMA-ES and TPE solvers, respectively. 

A key aspect of \optunity's design is interoperability with external environments. This requires bidirectional communication between \optunity's Python back-end ($\mathcal{O}$) and the external environment ($\mathcal{E}$) and roughly involves three steps: (i) $\mathcal{E}\rightarrow\mathcal{O}$ solver configuration, (ii) $\mathcal{O}\leftrightarrow\mathcal{E}$ objective function evaluations and (iii) $\mathcal{O}\rightarrow\mathcal{E}$ solution and solver summary. To this end, \optunity can do straightforward communication with any environment via sockets using JSON messages as shown in Figure~\ref{fig:workflow}. Only some information must be communicated, big objects like data sets are never exchanged. To port \optunity to a new environment, a thin wrapper must be implemented to handle communication.

\begin{figure}[!h]
  \centering 
      \includegraphics[width=\textwidth]{software.pdf} 
  \caption{Integrating \optunity in non-Python environments.}\label{fig:workflow}
\end{figure}

\subsection{Development and Documentation}
Collaborative development is organized via GitHub.\footnote{We maintain the following subdomains for convenience: \texttt{http://}$\{$\href{http://builds.optunity.net}{builds}, \href{http://docs.optunity.net}{docs}, \href{http://git.optunity.net}{git}, \href{http://issues.optunity.net}{issues}$\}$\texttt{.optunity.net}.} The project's master branch is kept stable and is subjected to continuous integration tests using Travis CI. 
We recommend prospective users to clone the master branch for the most up-to-date stable version of the software. Bug reports and feature requests can be filed via issues on GitHub. Future development efforts will focus on wrappers for Java and C/C++. We additionally plan to incorporate Bayesian optimizers which have no reference implementation in other packages. %Bayesian optimization strategies that are unavailable elsewhere \citep{jones1998efficient}. 

Code is documented using Sphinx and contains many doctests that can serve as both unit tests and examples of the associated functions. 
Our website contains API documentation, user documentation and a wide range of examples to illustrate all aspects of the software. 
The examples involve various packages and environments, including \textsc{scikit-learn} \citep{pedregosa2011scikit}, \textsc{OpenCV} and \textsc{Spark}'s \textsc{MLlib} \citep{zaharia2010spark}.
%Finally, some practical applications are available, including object recognition using OpenCV \citep{opencv_library} and deep learning with Theano \citep{bergstra2011theano}. % and semisupervised learning \citep{claesen2014robust}.

%\section{Conclusions}
%Optunity contains a variety of optimization methods that can be used for hyperparameter search. Using proper search methods becomes particularly important for machine learning methods with many hyperparameters, such as convolutional networks, deep belief networks and ensembles of SVM models.

\section{Related Work}

A number of software solutions exist for hyperparameter search. \textsc{Hyperopt} offers random search and sequential model-based optimization \citep{bergstra2013hyperopt}. Some packages dedicated to Bayesian approaches include \textsc{Spearmint} \citep{snoek2012practical}, \textsc{DiceKriging} \citep{roustant2012dicekriging}. Finally, \textsc{ParamILS} is a command-line-only tuning framework providing iterated local search \citep{hutter2009paramils}. 

%Existing packages tend to be one-trick ponies, providing a specific class of optimization methods and offering limited support to users in different machine learning environments. 
\optunity distinguishes itself from other packages by exposing a variety of fundamentally different solvers through a lightweight API. \optunity's client-server model facilitates integration in any language and environment and can even be used to run solvers remotely.

\section{Solver Performance Benchmark}
\textsc{Optunity}'s particle swarm optimizer (PSO) was compared to \textsc{Hyperopt}'s tree of Parzen estimators (TPE) in minimizing the Rastrigin function $f(x, y) = 20 + x^2 - 10 \cos(2\pi x) + y^2 - 10 \cos(2\pi y)$, which has a known optimum $f(0,0)=0$.
%\begin{equation}
%f(x, y) = 20 + x^2 - 10 \cos(2\pi x) + y^2 - 10 \cos(2\pi y), \quad \text{optimum: } f(0, 0) = 0 \label{eq:rastrigin},
%\end{equation}
Optimization was done uniformly within box constraints $|x|, |y| < 5.12$. We used the Rastrigin function because it has many local minima, as is common in hyperparameter search \citep{claesen2015hyperparameter}. Figure~\ref{fig:benchmark} shows that both PSO and TPE outperform random search. TPE is marginally better than PSO initially (few evaluations) while PSO converges much faster later on. PSO has also been shown to be competitive to TPE in tuning RBMs by Papa et al. \citep{papa2015model}.

\begin{figure}[!h]
  \centering 
      \includegraphics[width=0.65\textwidth]{benchmark.pdf} \ \ 
      \includegraphics[width=0.32\textwidth]{rastrigin.pdf}\vfill
  \caption{Evolution of average error per solver while minimizing the \textsc{Rastrigin} function (contours depicted on the right) based on 1,000 repetitions. The winner line shows the statistically significant best solver per evaluation count, if any ($\alpha=5\%$).}\label{fig:benchmark}
\vspace{-3em}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Keep the following \cleardoublepage at the end of this file, 
% otherwise \includeonly includes empty pages.
\cleardoublepage

% vim: tw=70 nocindent expandtab foldmethod=marker foldmarker={{{}{,}{}}}
